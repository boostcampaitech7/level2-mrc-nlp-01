model:
  name: klue/bert-base

seed: 42

training:
  epochs: 1 # HF default = 3
  batch_size: 32 # HF default = 8
  learning_rate: 5e-5 # HF default = 5e-5
  optimizer: AdamW # HF default = AdamW
  loss: L1loss # Not Implementedd
  shuffle: True # Not Implemented
  weight_decay: 0 # HF default = 0.0
  scheduler: linear # HF default = "linear"

dataRetrieval:
  eval: True
  context_path: ../data/wikipedia_documents.json
  top_k: 5
  faiss:
    use: False
    num_clusters: 64

dataQA:
  path: ../data/train_dataset
  tokenizer:
    max_seq_length: 384
    max_answer_length: 30
    doc_stride: 128
    pad_to_max_length: True
    preprocessing_num_wrokers: 
    overwrite_cache: False

  preprocess:
    - method: your-preprocess-method
      params:
        p: 0.0

  augmentation:
    # - method: your-augementation-method
    #   params:
    #     p: 0.0

testing:
  