output_dir ./outputs/train_dataset
Debug: config.dataRetrieval = {'type': 'hybrid1', 'eval': True, 'context_path': '/data/ephemeral/home/ksw/level2-mrc-nlp-01/data/wikipedia_documents.json', 'top_k': 10, 'hybrid_ratio': 0.5, 'faiss': {'use': False, 'num_clusters': 64}}
Debug: config.dataRetrieval.context_path = /data/ephemeral/home/ksw/level2-mrc-nlp-01/data/wikipedia_documents.json
Debug: config.dataRetrieval = {'type': 'hybrid1', 'eval': True, 'context_path': '/data/ephemeral/home/ksw/level2-mrc-nlp-01/data/wikipedia_documents.json', 'top_k': 10, 'hybrid_ratio': 0.5, 'faiss': {'use': False, 'num_clusters': 64}}
Debug: config.dataRetrieval.context_path = /data/ephemeral/home/ksw/level2-mrc-nlp-01/data/wikipedia_documents.json
Debug: context_path = /data/ephemeral/home/ksw/level2-mrc-nlp-01/data/wikipedia_documents.json
Lengths of unique contexts : 56737
Lengths of unique contexts : 56737
Debug: dense_retriever.context_path = /data/ephemeral/home/ksw/level2-mrc-nlp-01/data/wikipedia_documents.json
Debug: dense_retriever.model_name = klue/bert-base
Debug: Initializing Hybrid1StageRetrieval
Initializing Hybrid1StageRetrieval
Debug: config.dataRetrieval = {'type': 'hybrid1', 'eval': True, 'context_path': '/data/ephemeral/home/ksw/level2-mrc-nlp-01/data/wikipedia_documents.json', 'top_k': 10, 'hybrid_ratio': 0.5, 'faiss': {'use': False, 'num_clusters': 64}}
Initializing hybrid_1stage with ratio: 0.5
Initializing hybrid_1stage with top_k: 10
Hybrid1StageRetrieval initialized
Debug: config.dataRetrieval = {'type': 'hybrid1', 'eval': True, 'context_path': '/data/ephemeral/home/ksw/level2-mrc-nlp-01/data/wikipedia_documents.json', 'top_k': 10, 'hybrid_ratio': 0.5, 'faiss': {'use': False, 'num_clusters': 64}}
Debug: config.dataRetrieval.hybrid_ratio = 0.5
Debug: Hybrid1StageRetrieval initialized
Debug: Hybrid1StageRetrieval initialized with ratio: 0.5
Retrieving with top_k: 10
Using hybrid ratio: 0.5
-----------BM25 pickle loaded.-----------
get_relevant_doc_bulk 실행중 queries의 개수는  240
get_relevant_doc_bulk 실행중 queries의 type은  <class 'list'>
Processing queries: 100%|██████████████████████████████████████████████████████████████| 240/240 [03:41<00:00,  1.09it/s]
[query exhaustive search] done in 225.463 s
Computed and saved retrieval results.
Shape of doc_indices: (240, 10)
Length of query_or_dataset: 240
Sparse retrieval: 100%|██████████████████████████████████████████████████████████████| 240/240 [00:00<00:00, 7188.85it/s]
Traceback (most recent call last):
  File "/data/ephemeral/home/ksw/level2-mrc-nlp-01/src/main.py", line 533, in <module>
    main()
  File "/data/ephemeral/home/ksw/level2-mrc-nlp-01/src/main.py", line 530, in main
    do_retrieval(config, training_args, logger, is_testing)
  File "/data/ephemeral/home/ksw/level2-mrc-nlp-01/src/main.py", line 421, in do_retrieval
    df = retriever.retrieve(validation_dataset, topk=k)
  File "/data/ephemeral/home/ksw/level2-mrc-nlp-01/src/Retrieval/hybrid_1stage.py", line 58, in retrieve
    dense_results = self.dense_retriever.retrieve(dataset, topk=topk)
  File "/data/ephemeral/home/ksw/level2-mrc-nlp-01/src/Retrieval/dense_retrieval.py", line 348, in retrieve
    assert self.p_embeddings is not None, "get_dense_embedding() 메소드를 먼저 수행해줘야합니다."
AssertionError: get_dense_embedding() 메소드를 먼저 수행해줘야합니다.
